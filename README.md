# Project Title: Dog & Cat Image Classifier (Transfer Learning) ðŸ¾

## ðŸ”­ Overview

- **Goal:** Classify images as either "dog" or "cat" using deep learning.
- **Category:** *Supervised Image Classification* (Binary Classification).
- **Approach:** Download & organize data â†’ Preprocess images (rescaling, augmentation) â†’ Load pre-trained **VGG16** model (freeze base) â†’ Build and train custom classification head â†’ Evaluate on validation and test sets.
- **Baseline result (your run):** `Test Accuracy â‰ˆ 0.90-0.95+`. Demonstrates strong performance with transfer learning.

## ðŸ“¦ Dataset

- **Source:** Dogs vs. Cats dataset from Kaggle.
- **Files Used:**
    - Images from `train.zip`: Used for training and validation.
    - Images from `test1.zip`: Used for final model evaluation on unseen data.
- **Labels:** Binary classification: images are implicitly labeled "cat" or "dog" based on their respective subfolders.

> Note: The original Kaggle test1.zip is unlabeled; for evaluation, you'll organize it into cats/ and dogs/ subfolders as if they were labeled for local testing purposes.
> 

## ðŸ—‚ Project Structure

```
.
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ transfer_learning_dog_cat.ipynb  <-- Your Jupyter Notebook
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/                         <-- Training images organized into subfolders
â”‚   â”‚   â”œâ”€â”€ cats/
â”‚   â”‚   â””â”€â”€ dogs/
â”‚   â””â”€â”€ test/                          <-- Test images organized into subfolders
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

```

## ðŸ§° Environment & Requirements

- Python **3.8+**
- Recommended packages:
    
    ```
    tensorflow
    matplotlib
    numpy
    jupyter
    
    ```
    

**Install**

```
pip install tensorflow matplotlib numpy jupyter

```

## ðŸ§¹ Preprocessing & Data Loading

Images are loaded and preprocessed using Keras's `ImageDataGenerator`. This utility handles:

- **Rescaling:** Pixel values are normalized from `[0, 255]` to `[0, 1]`.
- **Data Augmentation (for training data):** Random transformations (rotation, shifts, zooms, flips) are applied on-the-fly to increase dataset diversity and reduce overfitting.
- **Batching:** Images are loaded in batches for efficient training.
- **Validation Split:** A portion of the training data is automatically set aside for validation during training.

Example (Python, within `transfer_learning_dog_cat.ipynb`):

```
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMAGE_SIZE = (150, 150)
BATCH_SIZE = 32
train_dir = '../data/train' # Path from notebook to training data
test_dir = '../data/test'   # Path from notebook to test data

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2
)

test_datagen = ImageDataGenerator(rescale=1./255) # No augmentation for test

train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,
    class_mode='binary', subset='training'
)
validation_generator = train_datagen.flow_from_directory(
    train_dir, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,
    class_mode='binary', subset='validation'
)
test_generator = test_datagen.flow_from_directory(
    test_dir, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,
    class_mode='binary', shuffle=False # Keep order for potential analysis
)

```

## ðŸ§  Model Architecture (Transfer Learning)

The model uses a pre-trained **VGG16 convolutional base** for feature extraction and a custom classification head.

```
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models

# Load VGG16 pre-trained on ImageNet, without its top classification layers
conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))

# Freeze the weights of the pre-trained convolutional base
conv_base.trainable = False

# Build the Sequential model with VGG16 base and a custom head
model = models.Sequential([
    conv_base,                       # The frozen VGG16 feature extractor
    layers.Flatten(),                # Flatten the output for dense layers
    layers.Dense(256, activation='relu'), # Hidden dense layer
    layers.Dropout(0.5),             # Dropout for regularization
    layers.Dense(1, activation='sigmoid') # Output layer for binary classification
])

model.summary()

```

## ðŸ‹ï¸â€â™‚ï¸ Training & Evaluation

The model is compiled with the Adam optimizer and `binary_crossentropy` loss. Training is performed on batches generated by `ImageDataGenerator`, followed by evaluation on a separate test set.

```
import tensorflow as tf

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model using the data generators
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // BATCH_SIZE,
    epochs=10, # Example: Can be adjusted
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // BATCH_SIZE
)

# Evaluate the model on the dedicated test set
print("\n--- Evaluating on Test Data ---")
test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)

print(f'\nFinal Test Loss: {test_loss:.4f}')
print(f'Final Test Accuracy: {test_acc:.4f}')

```

## ðŸ§ª Model Comparisons (Drop-in)

While not explicitly implemented in this blueprint beyond VGG16, you could explore and compare:

- **Other Pre-trained Models:** Easily swap `VGG16` with `ResNet50`, `InceptionV3`, `EfficientNetB0`, etc., from `tensorflow.keras.applications`.
- **Different Classification Heads:** Experiment with varying numbers of dense layers, neurons, or dropout rates.

**Expectations:**

- **VGG16:** Strong baseline for feature extraction due to pre-training on ImageNet.
- **ResNet/EfficientNet:** Often offer even better performance due to more advanced architectures and deeper layers, but might be slower to train/infer without GPU.

**Quick knobs to try:**

- Adjust `learning_rate` in the optimizer.
- Change `epochs` to find optimal training duration.
- Experiment with `Dropout` rates.
- Unfreeze and fine-tune a small portion of `conv_base` layers after initial training.

## ðŸ“¤ Inference on New Images (Optional)

```
import numpy as np
import os
# Function to load and preprocess a single image for prediction
def load_and_preprocess_image(img_path, target_size=IMAGE_SIZE):
    img = tf.keras.utils.load_img(img_path, target_size=target_size)
    img_array = tf.keras.utils.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) # Add batch dimension
    img_array /= 255.0 # Rescale
    return img_array

# Example prediction on a sample dog image (adjust path as needed)
# Ensure you have a sample image in your data/test/dogs folder
sample_image_path = os.path.join(test_dir, 'dogs', 'dog.123.jpg') # Example path

if os.path.exists(sample_image_path):
    preprocessed_image = load_and_preprocess_image(sample_image_path)
    prediction = model.predict(preprocessed_image)[0][0] # Output is a single probability

    predicted_label = "Dog" if prediction > 0.5 else "Cat"
    confidence = prediction if prediction > 0.5 else (1 - prediction)

    print(f"Image: {sample_image_path.split('/')[-1]}")
    print(f"Predicted: {predicted_label} with {confidence*100:.2f}% confidence")
else:
    print(f"Sample image not found at: {sample_image_path}")

```

## ðŸ§ª Diagnostics & Error Analysis (Recommended)

- **Training Plots:** Analyze accuracy and loss curves for both training and validation sets to detect overfitting or underfitting.
- **Confusion Matrix:** Generate a confusion matrix on the test set to understand per-class misclassifications.
- **Inspect Misclassified Images:** Manually review images that the model got wrong to identify common patterns or challenges (e.g., blurry images, difficult angles, occlusions).
- **Class Activation Maps (CAMs):** (Advanced) Visualize which parts of an image the CNN focused on to make its prediction.

## ðŸ—º Roadmap / Upgrades

1. **Fine-tuning the Base Model:** After initial training, unfreeze the top few layers of the `conv_base` and re-train the entire model with a very small learning rate for further performance gains.
2. **Advanced Augmentation:** Implement more sophisticated data augmentation strategies (e.g., CutMix, Mixup).
3. **Cross-Validation:** Use K-Fold cross-validation for more robust model evaluation, especially with smaller datasets.
4. **Ensembling Models:** Train multiple models (e.g., VGG16, ResNet, EfficientNet) and combine their predictions.
5. **Deployment:** Create a simple web application (e.g., with Flask/FastAPI) where users can upload an image and get a prediction.

## ðŸ“Ž Attribution

- Dataset Â© original providers (see Kaggle page for license/terms).

## ðŸ“œ License

This repository contains code for educational/research purposes. Respect the datasetâ€™s original license and Kaggleâ€™s terms of use.

## Contact

If you have any questions or feedback, feel free to reach out:

- GitHub: [@ElkattoufiMohamed](https://github.com/ElkattoufiMohamed)
- Email: contact@mohamedelkattoufi.com
